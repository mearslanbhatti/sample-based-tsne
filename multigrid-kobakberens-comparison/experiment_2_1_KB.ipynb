{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d101b3",
   "metadata": {},
   "source": [
    "# Kobak and Berens approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d52433",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_mnist, load_wong\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# the path should point to the FIt-SNE directory\u001b[39;00m\n\u001b[0;32m     20\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../FIt-SNE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_style('ticks')\n",
    "\n",
    "from pathlib import Path\n",
    "from src.utils.load_dataset import get_mnist, load_wong\n",
    "\n",
    "# the path should point to the FIt-SNE directory\n",
    "sys.path.append('../FIt-SNE')\n",
    "from fast_tsne import fast_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ec13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory relative to the notebook\n",
    "data_root = Path(\"..\") / \"data\"\n",
    "\n",
    "\n",
    "def get_dataset(dataset_id):\n",
    "    \"\"\"\n",
    "    Given the name of a data set, load the corresponding data set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : String\n",
    "        Number of points to be embedded in total\n",
    "    Returns\n",
    "    -------\n",
    "    dataset_id, X, labels : String, CSR_matrix, list[]\n",
    "        Name of the data set, the data, data labels\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset_id == \"mnist\":\n",
    "        print(\"Loading MNIST data\")\n",
    "        return [\"mnist\", ] + list(get_mnist(data_root / \"mnist\"))\n",
    "    elif dataset_id == \"wong\":\n",
    "        return [\"wong\", *load_wong(data_home=data_root / \"wong\", labels_name=\"broad\", return_colors=False)]\n",
    "    else:\n",
    "        print(\"[perp-vs-num_samples] Dataset `{}` not supported.\".format(dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabf581",
   "metadata": {},
   "source": [
    "#### plotting and saving logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927df36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_kb_tsne_embedding(embedding, labels, quality, title=\"kb-tsne embedding\", panel_letter=None):\n",
    "    \"\"\"\n",
    "    Plot a 2D t-SNE embedding with quality metrics annotated on the figure.\n",
    "\n",
    "    Parameters:\n",
    "        embedding (np.ndarray): 2D embedding of shape (n_samples, 2).\n",
    "        labels (np.ndarray): Cluster/class labels for each point.\n",
    "        quality (tuple): (kNN, KNC, CPD) metrics.\n",
    "        title (str): Title of the plot.\n",
    "        panel_letter (str or None): Optional panel letter for annotation.\n",
    "    \"\"\"\n",
    "    knn, knc, cpd = quality\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "    ax.scatter(\n",
    "        embedding[:, 0], embedding[:, 1],\n",
    "        s=2, c=labels, cmap=\"tab10\", edgecolor='none', rasterized=True\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, va='center')\n",
    "    ax.text(0.75, .02, 'KNN:\\nKNC:\\nCPD:', transform=ax.transAxes, fontsize=16)\n",
    "    ax.text(0.87, .02, '{:.2f}\\n{:.2f}\\n{:.2f}'.format(knn, knc, cpd), transform=ax.transAxes, fontsize=16)\n",
    "\n",
    "    if panel_letter:\n",
    "        ax.text(0, 1.05, panel_letter, transform=ax.transAxes, fontsize=8, fontweight='bold')\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    sns.despine(ax=ax, left=True, bottom=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(figure, dataset_id, fname, overwrite=False):\n",
    "\n",
    "    # Get current date formatted as dd-mm-yy\n",
    "    folder_timestamp = datetime.now().strftime(\"%d-%m-%y\")\n",
    "\n",
    "    if dataset_id is not None:\n",
    "        figures_dir = Path.cwd() / \"figures\" / \"kobak-berens\" /dataset_id / folder_timestamp\n",
    "        figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        # Default figures directory\n",
    "        figures_dir = Path.cwd() / \"figures\" / \"kobak-berens\" / \"default\"\n",
    "        figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    full_path = figures_dir / fname\n",
    "\n",
    "    if full_path.exists() and not overwrite:\n",
    "        print(f\"File already exists. Remove or rename {full_path} before continuing.\")\n",
    "    else:\n",
    "        figure.savefig(full_path)\n",
    "        print(f\"Figure saved to {full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c700ff7",
   "metadata": {},
   "source": [
    "#### Kobak and Berens approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kb_tsne(\n",
    "    initial_embedding,\n",
    "    rnd_state=42,\n",
    "    sample_rate=None\n",
    "):\n",
    "    \n",
    "    start = time()\n",
    "    n = initial_embedding.shape[0]\n",
    "    print(f\"Number of points in the dataset: {n}\")\n",
    "    if n <= 100000:\n",
    "        print(\"Dataset is small enough, running fast_tsne directly on the full dataset.\")\n",
    "        # Small dataset: combine perplexities [30, n/100]\n",
    "        perplist = [30]\n",
    "        if n / 100 > 30:\n",
    "            perplist.append(n / 100)\n",
    "        search_k = int(3 * max(perplist) * 50)  # 50 is the default n_trees\n",
    "        print(\"Applying fast_tsne for the small dataset with perplexities:\", perplist)\n",
    "        embedding = fast_tsne(\n",
    "            initial_embedding,\n",
    "            perplexity=0,\n",
    "            perplexity_list=perplist,\n",
    "            search_k=search_k,\n",
    "            \n",
    "            early_exag_coeff=12,\n",
    "            stop_early_exag_iter=250,\n",
    "            max_iter=1000,\n",
    "            \n",
    "            learning_rate=\"auto\",\n",
    "            momentum=0.5,\n",
    "            final_momentum=0.8,\n",
    "\n",
    "            initialization=\"pca\",\n",
    "            seed=rnd_state\n",
    "        )\n",
    "        print(\"DONE.\")\n",
    "    else:\n",
    "        # Very large dataset: sample then prolong\n",
    "        print(\"Dataset is too large, sampling and prolonging the embedding...\")\n",
    "        np.random.seed(rnd_state)\n",
    "        sample_ids = np.random.choice(\n",
    "            np.arange(0, n),\n",
    "            size=int(n * sample_rate),\n",
    "            replace=False\n",
    "        )\n",
    "        sample_ids.sort()\n",
    "        sampled_initial_embedding = initial_embedding[sample_ids, :]\n",
    "\n",
    "        m = sampled_initial_embedding.shape[0]  # or: int(n * sample_rate)\n",
    "        print(f\"Sampled {m} points from the dataset.\")\n",
    "        perplist = [30]\n",
    "        if m / 100 > 30:\n",
    "            perplist.append(m / 100)\n",
    "\n",
    "\n",
    "        search_k = int(3 * max(perplist) * 50)\n",
    "        print(\"Applying fast_tsne for the sampled dataset with perplexities:\", perplist)\n",
    "        sampled_embedding = fast_tsne(\n",
    "            sampled_initial_embedding,\n",
    "            perplexity=0,\n",
    "            perplexity_list=perplist,\n",
    "            search_k=search_k,\n",
    "            initialization=\"pca\",\n",
    "            seed=rnd_state,\n",
    "            \n",
    "            early_exag_coeff=12, # default value\n",
    "            stop_early_exag_iter=250, # default value\n",
    "            max_iter=1000, # default value\n",
    "            \n",
    "            learning_rate=\"auto\", # internally becomes max(200, n/early_exag_coeff)\n",
    "            momentum=0.5, # defualt value\n",
    "            final_momentum=0.8 # default value\n",
    "        )\n",
    "        print(\"DONE.\")\n",
    "\n",
    "\n",
    "        print(\"Prolongating the sampled embedding to full embedding...\")\n",
    "        # Prolongate the sampled embedding to the full dataset\n",
    "        prolongated_embedding = np.empty((n, 2))\n",
    "        prolongated_embedding[:] = np.NAN\n",
    "        prolongated_embedding[sample_ids, :] = sampled_embedding\n",
    "        nn = NearestNeighbors(n_neighbors=1).fit(sampled_initial_embedding)\n",
    "        dists, nearest = nn.kneighbors(initial_embedding)\n",
    "        for i in range(n):\n",
    "            if np.isnan(prolongated_embedding[i, 0]):\n",
    "                prolongated_embedding[i, :] = sampled_embedding[nearest[i, 0]]\n",
    "        print(\"DONE.\")\n",
    "        \n",
    "\n",
    "        print(\"Applying fast_tsne on the prolongated embedding...\")\n",
    "        embedding = fast_tsne(\n",
    "            initial_embedding,\n",
    "            perplexity=30,\n",
    "            initialization=prolongated_embedding,\n",
    "            seed=rnd_state,\n",
    "            \n",
    "            # early_exag_coeff=12, # default value\n",
    "            # stop_early_exag_iter=250, # default value\n",
    "            # late_exag_coeff=4,\n",
    "            # start_late_exag_iter=250, # not explicitly needed to be set, but good to have\n",
    "            # max_iter=750,\n",
    "\n",
    "            early_exag_coeff=1.0, # no early exaggeration\n",
    "            stop_early_exag_iter=0,\n",
    "            max_iter=750,\n",
    "\n",
    "            learning_rate=\"auto\",\n",
    "            momentum=0.5,\n",
    "            final_momentum=0.5\n",
    "        )\n",
    "        print(\"DONE.\")\n",
    "\n",
    "    print(f\"-> Total time for running kb_tsne took {(time() - start) / 60:.2f} minutes.\")\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb5c57",
   "metadata": {},
   "source": [
    "#### Embedding Quality method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea14ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def embedding_quality(X, Z, classes, knn=10, knn_classes=4, subsetsize=1000):\n",
    "    # Local neighborhood preservation (kNN)\n",
    "    nbrs1 = NearestNeighbors(n_neighbors=knn).fit(X)\n",
    "    ind1 = nbrs1.kneighbors(return_distance=False)\n",
    "\n",
    "    nbrs2 = NearestNeighbors(n_neighbors=knn).fit(Z)\n",
    "    ind2 = nbrs2.kneighbors(return_distance=False)\n",
    "\n",
    "    intersections = 0.0\n",
    "    for i in range(X.shape[0]):\n",
    "        intersections += len(set(ind1[i]) & set(ind2[i]))\n",
    "    mnn = intersections / (X.shape[0] * knn)\n",
    "\n",
    "    # Global neighborhood consistency (KNC)\n",
    "    cl, cl_inv = np.unique(classes, return_inverse=True)\n",
    "    C = cl.size\n",
    "\n",
    "    mu1 = np.zeros((C, X.shape[1]))\n",
    "    mu2 = np.zeros((C, Z.shape[1]))\n",
    "    for c in range(C):\n",
    "        mu1[c, :] = np.mean(X[cl_inv == c, :], axis=0)\n",
    "        mu2[c, :] = np.mean(Z[cl_inv == c, :], axis=0)\n",
    "\n",
    "    knn_classes = min(knn_classes, max(1, C - 1))  # Prevent requesting more neighbors than class centers\n",
    "    nbrs1 = NearestNeighbors(n_neighbors=knn_classes).fit(mu1)\n",
    "    ind1 = nbrs1.kneighbors(return_distance=False)\n",
    "\n",
    "    nbrs2 = NearestNeighbors(n_neighbors=knn_classes).fit(mu2)\n",
    "    ind2 = nbrs2.kneighbors(return_distance=False)\n",
    "\n",
    "    intersections = 0.0\n",
    "    for i in range(C):\n",
    "        intersections += len(set(ind1[i]) & set(ind2[i]))\n",
    "    mnn_global = intersections / (C * knn_classes)\n",
    "\n",
    "    # Spearman correlation of pairwise distances (CPD)\n",
    "    subset = np.random.choice(X.shape[0], size=subsetsize, replace=False)\n",
    "    d1 = pdist(X[subset, :])\n",
    "    d2 = pdist(Z[subset, :])\n",
    "    rho = spearmanr(d1, d2).correlation\n",
    "\n",
    "    return mnn, mnn_global, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aed7d1",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets a fixed seed for any randomized operations (e.g., random sampling, PCA initialization, t-SNE optimization). \n",
    "# Using a fixed random seed ensures reproducibility â€” so you get the same results every time you run the code.\n",
    "# random_state = 42\n",
    "\n",
    "# data to be used for the experiment\n",
    "dataset_id = \"mnist\"\n",
    "# dataset_id = \"c_elegans\"\n",
    "# dataset_id = \"wong\"\n",
    "# dataset_id = \"flow18\"\n",
    "\n",
    "# Load data\n",
    "dataset_name, data_to_be_embedded, labels = get_dataset(dataset_id)\n",
    "\n",
    "# size of the dataset\n",
    "num_points = data_to_be_embedded.shape[0]\n",
    "num_features = data_to_be_embedded.shape[1]\n",
    "print(f\"Dataset `{dataset_name}` has {num_points} points with {num_features} features each.\")\n",
    "print(\"Number of unique classes:\", len(np.unique(labels)))\n",
    "\n",
    "# for c_elegans, Convert sparse matrix to dense if necessary\n",
    "if dataset_id == \"c_elegans\":\n",
    "    if hasattr(data_to_be_embedded, \"toarray\"):\n",
    "        data_to_be_embedded = data_to_be_embedded.toarray()\n",
    "\n",
    "# Reduce dataset size for flow18\n",
    "if dataset_id == \"flow18\":\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    subset_indices = rng.choice(num_points, size=num_points // 2, replace=False)\n",
    "    data_to_be_embedded = data_to_be_embedded[subset_indices]\n",
    "    labels = labels[subset_indices]\n",
    "    print(f\"Reduced dataset size to {data_to_be_embedded.shape[0]} points for flow18.\")\n",
    "\n",
    "# Apply PCA to reduce dimensions to 50\n",
    "print(\"Applying PCA...\")\n",
    "# Centering the data.\n",
    "data_to_be_embedded = data_to_be_embedded - data_to_be_embedded.mean(axis=0)\n",
    "# Decomposing it via SVD.\n",
    "U, s, V = np.linalg.svd(data_to_be_embedded, full_matrices=False)\n",
    "U[:, np.sum(V, axis=1) < 0] *= -1\n",
    "# Projecting onto the top components via U * s.\n",
    "data_to_be_embedded = np.dot(U, np.diag(s))\n",
    "initial_embedding = data_to_be_embedded[:, np.argsort(s)[::-1]][:, :50]\n",
    "print(\"Done.\")\n",
    "\n",
    "# sampling rate\n",
    "sample_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc49467",
   "metadata": {},
   "source": [
    "### Run kb_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kb_tsne\n",
    "print(\"Running kb_tsne...\")\n",
    "kb_output = kb_tsne(\n",
    "    initial_embedding=initial_embedding,\n",
    "    rnd_state=42,\n",
    "    sample_rate=sample_rate\n",
    ")\n",
    "print(\"finished running kb_tsne.\")\n",
    "\n",
    "final_embedding = kb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0999e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embedding = kb_output\n",
    "subset_size = 1000\n",
    "\n",
    "kb_mnn, kb_knc, kb_cpd = embedding_quality(\n",
    "    initial_embedding, final_embedding, labels, knn=10, knn_classes=4, subsetsize=subset_size\n",
    ")\n",
    "\n",
    "print(f\"KB t-SNE:  kNN={kb_mnn:.4f}, KNC={kb_knc:.4f}, CPD={kb_cpd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d82380",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = (kb_mnn, kb_knc, kb_cpd)\n",
    "\n",
    "fig = plot_kb_tsne_embedding(\n",
    "    embedding=final_embedding,\n",
    "    labels=labels,\n",
    "    quality=quality,\n",
    "    title=\"\",\n",
    "    panel_letter=None\n",
    ")\n",
    "\n",
    "timestamp_kb = datetime.now().strftime(\"%d-%m-%y-%H-%M\")\n",
    "filename_kb = f\"{dataset_id}_~_{timestamp_kb}.png\"\n",
    "save_fig(fig, dataset_id, filename_kb, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0407c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-emb-exps-kb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
