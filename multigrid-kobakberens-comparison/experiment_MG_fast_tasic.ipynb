{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af1376e",
   "metadata": {},
   "source": [
    "# Analysing multigrid approach with fast_tsne implementation for tasic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e825507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rnaseqTools\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# the path should point to the FIt-SNE directory\u001b[39;00m\n\u001b[0;32m     22\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../FIt-SNE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr\n",
    "from scipy import sparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from src.utils import rnaseqTools\n",
    "\n",
    "# the path should point to the FIt-SNE directory\n",
    "sys.path.append('../FIt-SNE')\n",
    "from fast_tsne import fast_tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef64d56",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your data directory\n",
    "data_root = Path(\"..\") / \"data\"\n",
    "path_to_data = Path(data_root)\n",
    "\n",
    "path_to_data = Path(path_to_data)\n",
    "\n",
    "if path_to_data.joinpath(\"tasic2018.pickle\").exists():\n",
    "    print(\"[tasic2018] Pickle found. Loading it.\")\n",
    "    with open(str(path_to_data.joinpath(\"tasic2018.pickle\")), \"rb\") as f:\n",
    "        tasic2018 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    filename = path_to_data.joinpath(\"mouse_VISp_gene_expression_matrices_2018-06-14\",\n",
    "                                        \"mouse_VISp_2018-06-14_exon-matrix.csv\")\n",
    "    counts1, genes1, cells1 = rnaseqTools.sparseload(str(filename))\n",
    "\n",
    "    filename = path_to_data.joinpath(\"mouse_ALM_gene_expression_matrices_2018-06-14\",\n",
    "                                        \"mouse_ALM_2018-06-14_exon-matrix.csv\")\n",
    "    counts2, genes2, cells2 = rnaseqTools.sparseload(filename)\n",
    "\n",
    "    counts = sparse.vstack((counts1, counts2), format='csc')\n",
    "\n",
    "    cells = np.concatenate((cells1, cells2))\n",
    "\n",
    "    if np.all(genes1 == genes2):\n",
    "        genes = np.copy(genes1)\n",
    "\n",
    "    filename = path_to_data.joinpath(\"mouse_VISp_gene_expression_matrices_2018-06-14\",\n",
    "                                        \"mouse_VISp_2018-06-14_genes-rows.csv\")\n",
    "    genesDF = pd.read_csv(str(filename))\n",
    "    ids = genesDF['gene_entrez_id'].tolist()\n",
    "    symbols = genesDF['gene_symbol'].tolist()\n",
    "    id2symbol = dict(zip(ids, symbols))\n",
    "    genes = np.array([id2symbol[g] for g in genes])\n",
    "\n",
    "    filename = path_to_data.joinpath(\"tasic-sample_heatmap_plot_data.csv\")\n",
    "    clusterInfo = pd.read_csv(str(filename))\n",
    "    goodCells = clusterInfo['sample_name'].values\n",
    "    ids = clusterInfo['cluster_id'].values\n",
    "    labels = clusterInfo['cluster_label'].values\n",
    "    colors = clusterInfo['cluster_color'].values\n",
    "\n",
    "    clusterNames = np.array([labels[ids == i + 1][0] for i in range(np.max(ids))])\n",
    "    clusterColors = np.array([colors[ids == i + 1][0] for i in range(np.max(ids))])\n",
    "    clusters = np.copy(ids)\n",
    "\n",
    "    ind = np.array([np.where(cells == c)[0][0] for c in goodCells])\n",
    "    counts = counts[ind, :]\n",
    "\n",
    "    areas = (ind < cells1.size).astype(int)\n",
    "\n",
    "    clusters = clusters - 1\n",
    "\n",
    "    markerGenes = ['Snap25', 'Gad1', 'Slc17a7', 'Pvalb', 'Sst', 'Vip', 'Aqp4',\n",
    "                    'Mog', 'Itgam', 'Pdgfra', 'Flt1', 'Bgn', 'Rorb', 'Foxp2']\n",
    "\n",
    "    tasic2018 = {'counts': counts, 'genes': genes, 'clusters': clusters, 'areas': areas,\n",
    "                    'clusterColors': clusterColors, 'clusterNames': clusterNames}\n",
    "\n",
    "    tasic2018[\"importantGenesTasic2018\"] = rnaseqTools.geneSelection(\n",
    "        tasic2018['counts'], n=3000, threshold=32)\n",
    "\n",
    "    with open(str(path_to_data.joinpath(\"tasic2018.pickle\")), \"wb\") as f:\n",
    "        pickle.dump(tasic2018, f)\n",
    "\n",
    "    print(tasic2018['counts'].shape)\n",
    "    print(np.sum(tasic2018['areas'] == 0))\n",
    "    print(np.sum(tasic2018['areas'] == 1))\n",
    "    print(np.unique(tasic2018['clusters']).size)\n",
    "\n",
    "# librarySizes = np.sum(tasic2018['counts'], axis=1)\n",
    "# X = np.log2(tasic2018['counts'][:, tasic2018[\"importantGenesTasic2018\"]] / librarySizes * 1e+6 + 1)\n",
    "# X = np.array(X)\n",
    "# X = X - X.mean(axis=0)\n",
    "# U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "# U[:, np.sum(V, axis=1) < 0] *= -1\n",
    "# X = np.dot(U, np.diag(s))\n",
    "# X = X[:, np.argsort(s)[::-1]][:, :50]\n",
    "\n",
    "labels = tasic2018[\"clusters\"]\n",
    "\n",
    "librarySizes = np.sum(tasic2018['counts'], axis=1).A1  # .A1 flattens the sparse matrix sum\n",
    "counts_selected = tasic2018['counts'][:, tasic2018[\"importantGenesTasic2018\"]].toarray()\n",
    "norm_counts = (counts_selected.T / librarySizes).T * 1e6\n",
    "X = np.log2(norm_counts + 1)\n",
    "X = X - X.mean(axis=0)\n",
    "data_to_be_embedded = X.copy()  # <--- This is your high-dimensional data\n",
    "\n",
    "# reduce dimensions to 50 using PCA\n",
    "U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "U[:, np.sum(V, axis=1) < 0] *= -1\n",
    "X = np.dot(U, np.diag(s))\n",
    "initial_embedding = X[:, np.argsort(s)[::-1]][:, :50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e71413",
   "metadata": {},
   "source": [
    "### Plot Embeddings Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ab576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_embeddings(results, tasic2018):\n",
    "\n",
    "    # Extract unique perplexity values\n",
    "    sample_perps = sorted(set(r[\"sample_perplexity\"] for r in results))\n",
    "    full_perps = sorted(set(r[\"full_perplexity\"] for r in results))\n",
    "    \n",
    "    rows = len(sample_perps)\n",
    "    cols = len(full_perps)\n",
    "\n",
    "    # Define cluster colors and classes for annotations\n",
    "    colors = tasic2018[\"clusterColors\"][tasic2018[\"clusters\"]]\n",
    "\n",
    "    classes = {\n",
    "        'Lamp5': [-35, -12, 'Lamp5 Lsp1'],\n",
    "        'Vip':   [15, 30, 'Vip Rspo4 Rxfp1 Chat'],\n",
    "        'Pvalb': [-4, 32, 'Pvalb Reln Tac1'],\n",
    "        'Sst':   [-32, 18, 'Sst Myh8 Fibin'],\n",
    "        'L2/3 IT': [-30, -30, 'L2/3 IT ALM Sla'],\n",
    "        'L5 IT': [-10, -25, 'L5 IT ALM Tnc'],\n",
    "        'L6 IT': [6, -4, 'L6 IT VISp Penk Col27a1'],\n",
    "        'L5 PT': [23, -25, 'L5 PT ALM Hpgd'],\n",
    "        'L5 NP': [-23, -40, 'L5 NP VISp Trhr Cpne7'],\n",
    "        'L6 CT': [30, 12, 'L6 CT VISp Nxph2 Wls'],\n",
    "        'L6b':   [35, -11, 'L6b P2ry12'],\n",
    "        'Non-neurons': [20, -20, 'Astro Aqp4']\n",
    "    }\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    # Map (sp, fp) â†’ result\n",
    "    result_map = {(r[\"sample_perplexity\"], r[\"full_perplexity\"]): r for r in results}\n",
    "\n",
    "    for i, sp in enumerate(sample_perps):\n",
    "        for j, fp in enumerate(full_perps):\n",
    "            ax = axes[i, j]\n",
    "            result = result_map.get((sp, fp), None)\n",
    "\n",
    "            if result is None:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            embedding = result[\"embedding\"]\n",
    "            quality = (\n",
    "                result.get(\"mnn\", 0),\n",
    "                result.get(\"knc\", 0),\n",
    "                result.get(\"cpd\", 0)\n",
    "            )\n",
    "\n",
    "            # Plot points\n",
    "            ax.set_aspect('equal', adjustable='datalim')\n",
    "            ax.scatter(\n",
    "                embedding[:, 0], embedding[:, 1],\n",
    "                s=2, c=colors, edgecolor='none', rasterized=True\n",
    "            )\n",
    "\n",
    "            # Title\n",
    "            title = f\"sample perplexity: {sp}\\nfull perplexity: {fp}\"\n",
    "            ax.set_title(title, fontsize=16)\n",
    "\n",
    "            # title = \"\"\n",
    "\n",
    "            # Cluster labels\n",
    "            for c in classes:\n",
    "                x, y, cname = classes[c]\n",
    "                cluster_idx = np.where(tasic2018['clusterNames'] == cname)[0]\n",
    "                color = tasic2018['clusterColors'][cluster_idx[0]] if cluster_idx.size > 0 else 'black'\n",
    "                ax.text(x, y, c, fontsize=6, color=color)\n",
    "\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            sns.despine(ax=ax, left=True, bottom=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a80eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_embedding_with_metrics(results, tasic2018):\n",
    "\n",
    "    # Extract unique perplexity values\n",
    "    sample_perps = sorted(set(r[\"sample_perplexity\"] for r in results))\n",
    "    full_perps = sorted(set(r[\"full_perplexity\"] for r in results))\n",
    "    \n",
    "    rows = len(sample_perps)\n",
    "    cols = len(full_perps)\n",
    "\n",
    "    # Define cluster colors and classes for annotations\n",
    "    colors = tasic2018[\"clusterColors\"][tasic2018[\"clusters\"]]\n",
    "\n",
    "    classes = {\n",
    "        'Lamp5': [-35, -12, 'Lamp5 Lsp1'],\n",
    "        'Vip':   [15, 30, 'Vip Rspo4 Rxfp1 Chat'],\n",
    "        'Pvalb': [-4, 32, 'Pvalb Reln Tac1'],\n",
    "        'Sst':   [-32, 18, 'Sst Myh8 Fibin'],\n",
    "        'L2/3 IT': [-30, -30, 'L2/3 IT ALM Sla'],\n",
    "        'L5 IT': [-10, -25, 'L5 IT ALM Tnc'],\n",
    "        'L6 IT': [6, -4, 'L6 IT VISp Penk Col27a1'],\n",
    "        'L5 PT': [23, -25, 'L5 PT ALM Hpgd'],\n",
    "        'L5 NP': [-23, -40, 'L5 NP VISp Trhr Cpne7'],\n",
    "        'L6 CT': [30, 12, 'L6 CT VISp Nxph2 Wls'],\n",
    "        'L6b':   [35, -11, 'L6b P2ry12'],\n",
    "        'Non-neurons': [20, -20, 'Astro Aqp4']\n",
    "    }\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    # Map (sp, fp) â†’ result\n",
    "    result_map = {(r[\"sample_perplexity\"], r[\"full_perplexity\"]): r for r in results}\n",
    "\n",
    "    for i, sp in enumerate(sample_perps):\n",
    "        for j, fp in enumerate(full_perps):\n",
    "            ax = axes[i, j]\n",
    "            result = result_map.get((sp, fp), None)\n",
    "\n",
    "            if result is None:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            embedding = result[\"embedding\"]\n",
    "            quality = (\n",
    "                result.get(\"mnn\", 0),\n",
    "                result.get(\"knc\", 0),\n",
    "                result.get(\"cpd\", 0)\n",
    "            )\n",
    "\n",
    "            # Plot points\n",
    "            ax.set_aspect('equal', adjustable='datalim')\n",
    "            ax.scatter(\n",
    "                embedding[:, 0], embedding[:, 1],\n",
    "                s=2, c=colors, edgecolor='none', rasterized=True\n",
    "            )\n",
    "\n",
    "            # Title\n",
    "            # title = f\"sample perplexity: {sp}\\nfull perplexity: {fp}\"\n",
    "            # ax.set_title(title, fontsize=10)\n",
    "            title = \"\"\n",
    "\n",
    "            # Quality metrics\n",
    "            ax.text(0.75, .02, 'KNN:\\nKNC:\\nCPD:', transform=ax.transAxes, fontsize=9)\n",
    "            ax.text(0.87, .02, '{:.2f}\\n{:.2f}\\n{:.2f}'.format(*quality), transform=ax.transAxes, fontsize=9)\n",
    "\n",
    "            # Cluster labels\n",
    "            for c in classes:\n",
    "                x, y, cname = classes[c]\n",
    "                cluster_idx = np.where(tasic2018['clusterNames'] == cname)[0]\n",
    "                color = tasic2018['clusterColors'][cluster_idx[0]] if cluster_idx.size > 0 else 'black'\n",
    "                ax.text(x, y, c, fontsize=6, color=color)\n",
    "\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            sns.despine(ax=ax, left=True, bottom=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(figure, dataset_id, fname, overwrite=False):\n",
    "\n",
    "    # Get current date formatted as dd-mm-yy\n",
    "    folder_timestamp = datetime.now().strftime(\"%d-%m-%y\")\n",
    "\n",
    "    if dataset_id is not None:\n",
    "        figures_dir = Path.cwd() / \"figures\" / \"multi-grid\" / \"fast_tsne\" / dataset_id / folder_timestamp\n",
    "        figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        # Default figures directory\n",
    "        figures_dir = Path.cwd() / \"figures\" / \"multi-grid\" / \"fast_tsne\" / \"default\"\n",
    "        figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    full_path = figures_dir / fname\n",
    "\n",
    "    if full_path.exists() and not overwrite:\n",
    "        print(f\"File already exists. Remove or rename {full_path} before continuing.\")\n",
    "    else:\n",
    "        figure.savefig(full_path)\n",
    "        print(f\"Figure saved to {full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab141a1",
   "metadata": {},
   "source": [
    "### mg_tsne with fast_tsne implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077dffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mg_tsne(\n",
    "    initial_embedding,\n",
    "    sample_rate,\n",
    "    sample_perplexity,\n",
    "    full_perplexity,\n",
    "    rnd_state=42\n",
    "):\n",
    "    \n",
    "    start = time()\n",
    "\n",
    "    # Sample the data\n",
    "    np.random.seed(rnd_state)\n",
    "    print(\"Sampling the data...\")\n",
    "    sample_ids = np.random.choice(\n",
    "        np.arange(0, initial_embedding.shape[0]),\n",
    "        size=int(initial_embedding.shape[0] * sample_rate),\n",
    "        replace=False\n",
    "    )\n",
    "    sample_ids.sort()\n",
    "    sampled_initial_embedding = initial_embedding[sample_ids, :]\n",
    "    sampled_pca_data = initial_embedding[sample_ids, :]\n",
    "    print(\"DONE.\")\n",
    "    \n",
    "\n",
    "    # Run fast_tsne on sampled data\n",
    "    # returns a 2D embedding\n",
    "    print(\"Applying fast_tsne on the sampled data...\")\n",
    "    initial_tSNE_embedding = fast_tsne(\n",
    "        sampled_initial_embedding,\n",
    "        perplexity=sample_perplexity,\n",
    "        initialization=\"pca\",\n",
    "        seed=rnd_state,\n",
    "        \n",
    "        early_exag_coeff=12,\n",
    "        stop_early_exag_iter=250,\n",
    "        max_iter=1000,\n",
    "        \n",
    "        learning_rate=\"auto\", # internally becomes max(200, n/early_exag_coeff), uses m sampled points so m/12\n",
    "        momentum=0.5,\n",
    "        final_momentum=0.8\n",
    "    )\n",
    "    print(\"DONE.\")\n",
    "\n",
    "\n",
    "    # Prolongation: Initialize full embedding with NaN and assign sample embeddings\n",
    "    print(\"Prolongating the sample embedding to the full dataset...\")\n",
    "    prolongated_embedding = np.empty((initial_embedding.shape[0], 2))\n",
    "    prolongated_embedding[:] = np.NAN\n",
    "    prolongated_embedding[sample_ids, :] = initial_tSNE_embedding\n",
    "    # Use nearest neighbor from sampled points for each unsampled point\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(sampled_pca_data)\n",
    "    dists, nearest = nn.kneighbors(initial_embedding)\n",
    "    for i in range(initial_embedding.shape[0]):\n",
    "        if np.isnan(prolongated_embedding[i, 0]):\n",
    "            prolongated_embedding[i, :] = initial_tSNE_embedding[nearest[i, 0]]\n",
    "    print(\"DONE.\")\n",
    "\n",
    "\n",
    "    # Run fast_tsne on full data using prolongated embedding as initialization\n",
    "    print(\"Applying fast_tsne on the full dataset with no exaggeration...\")\n",
    "    full_embedding = fast_tsne(\n",
    "        initial_embedding,\n",
    "        perplexity=full_perplexity,\n",
    "        initialization=prolongated_embedding,\n",
    "        seed=rnd_state,\n",
    "\n",
    "        early_exag_coeff=1.0, # no early exaggeration\n",
    "        stop_early_exag_iter=0,\n",
    "        max_iter=750,\n",
    "        \n",
    "        learning_rate=\"auto\", # internally becomes max(200, n/early_exag_coeff)\n",
    "        momentum=0.5,\n",
    "        final_momentum=0.5\n",
    "    )\n",
    "    print(\"DONE.\")\n",
    "\n",
    "\n",
    "    print(f\"-> Total time for running mg_tsne took {(time() - start) / 60:.2f} minutes.\")\n",
    "    return full_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c30c8",
   "metadata": {},
   "source": [
    "### Embedding Quality method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_quality(X, Z, classes, knn=10, knn_classes=4, subsetsize=1000):\n",
    "    # Local neighborhood preservation (kNN)\n",
    "    nbrs1 = NearestNeighbors(n_neighbors=knn).fit(X)\n",
    "    ind1 = nbrs1.kneighbors(return_distance=False)\n",
    "\n",
    "    nbrs2 = NearestNeighbors(n_neighbors=knn).fit(Z)\n",
    "    ind2 = nbrs2.kneighbors(return_distance=False)\n",
    "\n",
    "    intersections = 0.0\n",
    "    for i in range(X.shape[0]):\n",
    "        intersections += len(set(ind1[i]) & set(ind2[i]))\n",
    "    mnn = intersections / (X.shape[0] * knn)\n",
    "\n",
    "    # Global neighborhood consistency (KNC)\n",
    "    cl, cl_inv = np.unique(classes, return_inverse=True)\n",
    "    C = cl.size\n",
    "\n",
    "    mu1 = np.zeros((C, X.shape[1]))\n",
    "    mu2 = np.zeros((C, Z.shape[1]))\n",
    " \n",
    "    # compute the centroid of each class in both the high-dimensional space (mu1) and the embedding (mu2).\n",
    "    for c in range(C):\n",
    "        mu1[c, :] = np.mean(X[cl_inv == c, :], axis=0)\n",
    "        mu2[c, :] = np.mean(Z[cl_inv == c, :], axis=0)\n",
    "\n",
    "    knn_classes = min(knn_classes, max(1, C - 1))  # Prevent requesting more neighbors than class centers\n",
    "    nbrs1 = NearestNeighbors(n_neighbors=knn_classes).fit(mu1)\n",
    "    ind1 = nbrs1.kneighbors(return_distance=False)\n",
    "\n",
    "    nbrs2 = NearestNeighbors(n_neighbors=knn_classes).fit(mu2)\n",
    "    ind2 = nbrs2.kneighbors(return_distance=False)\n",
    "\n",
    "    intersections = 0.0\n",
    "    for i in range(C):\n",
    "        intersections += len(set(ind1[i]) & set(ind2[i]))\n",
    "    mnn_global = intersections / (C * knn_classes)\n",
    "\n",
    "    # Spearman correlation of pairwise distances (CPD)\n",
    "    subset = np.random.choice(X.shape[0], size=subsetsize, replace=False)\n",
    "    d1 = pdist(X[subset, :])\n",
    "    d2 = pdist(Z[subset, :])\n",
    "    rho = spearmanr(d1, d2).correlation\n",
    "\n",
    "    return mnn, mnn_global, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e4df0",
   "metadata": {},
   "source": [
    "### Run t-SNE row wise\n",
    "\n",
    "- calculates embedding quality of each embedding and adds it to the result's object for this embedding. All the qualities can be plotted row wise later\n",
    "- calculates CPD between embeddings across the row where the reference embedding is the first one.\n",
    "    - the plot is created after each row is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39243e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 0.1\n",
    "\n",
    "# tasic\n",
    "# sample_perplexities = [10, 30, 100, 300]\n",
    "# full_perplexities = [10, 30, 100, 300]\n",
    "# test perplexities\n",
    "sample_perplexities = [5]\n",
    "full_perplexities = [5]\n",
    "\n",
    "# Container to collect results\n",
    "results = []\n",
    "# cache for comparing embeddings across full_perps\n",
    "embedding_reference_by_sample_perp = {}\n",
    "cpd_between_embeddings_records = []\n",
    "\n",
    "# Run grid search over (sample_perplexity, full_perplexity)\n",
    "for sample_perp in sample_perplexities:\n",
    "    for full_perp in full_perplexities:\n",
    "\n",
    "        print(f\"Running for sample_perp={sample_perp}, full_perp={full_perp}...\")\n",
    "\n",
    "        # Step 2: Run mg_tsne\n",
    "        print(\"Running mg_tsne...\")\n",
    "        final_embedding = mg_tsne(\n",
    "            initial_embedding=initial_embedding,\n",
    "            sample_rate=sample_rate,\n",
    "            sample_perplexity=sample_perp,\n",
    "            full_perplexity=full_perp,\n",
    "            rnd_state=42\n",
    "        )\n",
    "        print(\"finished running mg_tsne.\")\n",
    "\n",
    "        # Compute embedding quality\n",
    "        print(\"Computing embedding quality metrics...\")\n",
    "        mnn, mnn_global, rho = embedding_quality(\n",
    "            X=initial_embedding,\n",
    "            Z=final_embedding,\n",
    "            classes=labels,\n",
    "            knn=10,\n",
    "            knn_classes=4,\n",
    "            subsetsize=1000\n",
    "        )\n",
    "        print(f\"Quality - mnn: {mnn:.3f}, knc: {mnn_global:.3f}, cpd: {rho:.3f}\")\n",
    "        \n",
    "\n",
    "        print(\"calculating CPD between the first embedding and this embedding...\")\n",
    "        # Subsample 1000 points to compute CPD\n",
    "        # Are we sampling the same points every time?\n",
    "        subset_indices = np.random.choice(final_embedding.shape[0], size=1000, replace=False)\n",
    "        emb_subset = final_embedding[subset_indices, :]\n",
    "        cpd_value = None\n",
    "\n",
    "        if sample_perp not in embedding_reference_by_sample_perp:\n",
    "            # Save this embedding as reference (for lowest full_perp or first time)\n",
    "            embedding_reference_by_sample_perp[sample_perp] = emb_subset\n",
    "        else:\n",
    "            # Compare with reference embedding\n",
    "            ref_embedding = embedding_reference_by_sample_perp[sample_perp]\n",
    "            d1 = pdist(ref_embedding)\n",
    "            d2 = pdist(emb_subset)\n",
    "            cpd_value = spearmanr(d1, d2).correlation\n",
    "\n",
    "            cpd_between_embeddings_records.append({\n",
    "                \"sample_perplexity\": sample_perp,\n",
    "                \"full_perplexity\": full_perp,\n",
    "                \"cpd_value\": cpd_value\n",
    "            })\n",
    "        print(f\"Done\")\n",
    "\n",
    "        # Store everything in results\n",
    "        results.append({\n",
    "            \"sample_perplexity\": sample_perp,\n",
    "            \"full_perplexity\": full_perp,\n",
    "            \"embedding\": final_embedding,\n",
    "            \"labels\": labels,\n",
    "            \"mnn\": mnn,\n",
    "            \"knc\": mnn_global,\n",
    "            \"cpd\": rho\n",
    "        })\n",
    "\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6da50",
   "metadata": {},
   "source": [
    "### Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add or remove the title, change in the plot_embeddings function\n",
    "figure = plot_embeddings(results, tasic2018)\n",
    "\n",
    "# save the figure\n",
    "file_name_timestamp = datetime.now().strftime(\"%H-%M-%S\")\n",
    "filename = f\"tasic_without_metrics~_{file_name_timestamp}.png\"\n",
    "save_fig(figure, \"tasic\", filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add or remove the title, change in the plot_embeddings function\n",
    "figure_metrics = plot_embedding_with_metrics(results, tasic2018)\n",
    "\n",
    "# save the figure\n",
    "file_name_timestamp = datetime.now().strftime(\"%H-%M-%S\")\n",
    "filename = f\"tasic_with_metrics~_{file_name_timestamp}.png\"\n",
    "save_fig(figure_metrics, \"tasic\", filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970560d7",
   "metadata": {},
   "source": [
    "#### Generate csv file containing cpd values between embeddings across the rows and save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the raw (long-form) CSV\n",
    "cpd_df = pd.DataFrame(cpd_between_embeddings_records)\n",
    "\n",
    "# Construct save path as per `save_fig`\n",
    "folder_timestamp = datetime.now().strftime(\"%d-%m-%y\")\n",
    "\n",
    "cpd_dir = Path.cwd() / \"figures\" / \"multi-grid\" / \"fast_tsne\" / \"tasic\" / folder_timestamp\n",
    "cpd_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Filename and save\n",
    "cpd_filename = f\"tasic_cpd_longform_{datetime.now().strftime('%H-%M-%S')}.csv\"\n",
    "cpd_path = cpd_dir / cpd_filename\n",
    "cpd_df.to_csv(cpd_path, index=False)\n",
    "print(f\"Saved CPD (long-form) to {cpd_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13cd1c9",
   "metadata": {},
   "source": [
    "#### Plot embedding quality for each individual embedding across the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20025160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert results into a DataFrame for easy grouping and plotting\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# For each unique sample_perplexity, plot metrics vs full_perplexity\n",
    "for sample_perp in df_results['sample_perplexity'].unique():\n",
    "    subset = df_results[df_results['sample_perplexity'] == sample_perp].sort_values(by=\"full_perplexity\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(subset['full_perplexity'], subset['mnn'], marker='o', label='kNN')\n",
    "    plt.plot(subset['full_perplexity'], subset['knc'], marker='s', label='KNC')\n",
    "    plt.plot(subset['full_perplexity'], subset['cpd'], marker='^', label='CPD')\n",
    "\n",
    "    plt.title(f\"Sample Perplexity: {sample_perp}\", fontsize=18)\n",
    "    # plt.title(\"\")\n",
    "    plt.xlabel(\"Full Perplexity\", fontsize=18)\n",
    "    plt.ylabel(\"Metric Value\", fontsize=18)\n",
    "\n",
    "    plt.xticks(fontsize=18)  # <-- tick label font size for x-axis\n",
    "    plt.yticks(fontsize=18)  # <-- tick label font size for y-axis\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    metric_plot_filename = f\"quality_metrics_sampleperp_{sample_perp}.png\"\n",
    "    save_fig(fig, \"tasic\", metric_plot_filename)\n",
    "    print(f\"Saved metric plot as {metric_plot_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb6548",
   "metadata": {},
   "source": [
    "#### Plot embedding quality for each individual embedding across the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for full_perp in df_results['full_perplexity'].unique():\n",
    "    subset = df_results[df_results['full_perplexity'] == full_perp].sort_values(by=\"sample_perplexity\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(subset['sample_perplexity'], subset['mnn'], marker='o', label='kNN')\n",
    "    plt.plot(subset['sample_perplexity'], subset['knc'], marker='s', label='KNC')\n",
    "    plt.plot(subset['sample_perplexity'], subset['cpd'], marker='^', label='CPD')\n",
    "\n",
    "    plt.title(f\"Full Perplexity: {full_perp}\", fontsize=18)\n",
    "    plt.xlabel(\"Sample Perplexity\", fontsize=18)\n",
    "    plt.ylabel(\"Metric Value\", fontsize=18)\n",
    "\n",
    "    plt.xticks(fontsize=18)  # <-- tick label font size for x-axis\n",
    "    plt.yticks(fontsize=18)  # <-- tick label font size for y-axis\n",
    "\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    metric_plot_filename = f\"quality_metrics_fullperp_{full_perp}.png\"\n",
    "    save_fig(fig, \"tasic\", metric_plot_filename)\n",
    "    print(f\"Saved metric plot as {metric_plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0f7e4",
   "metadata": {},
   "source": [
    "## Run t-SNE column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 0.1\n",
    "\n",
    "# tasic\n",
    "# sample_perplexities = [10, 30, 100, 300, 1000]\n",
    "# full_perplexities = [10, 30, 100, 300, 1000]\n",
    "# test perplexities\n",
    "sample_perplexities = [30]\n",
    "full_perplexities = [238.2]\n",
    "\n",
    "\n",
    "columnwise_results = []\n",
    "embedding_reference_by_full_perp = {}\n",
    "cpd_between_columns_records = []\n",
    "\n",
    "for full_perp in full_perplexities:\n",
    "    for sample_perp in sample_perplexities:\n",
    "\n",
    "        print(f\"Running for full_perp={full_perp}, sample_perp={sample_perp}...\")\n",
    "\n",
    "        # Run mg_tsne\n",
    "        final_embedding = mg_tsne(\n",
    "            initial_embedding=initial_embedding,\n",
    "            sample_rate=sample_rate,\n",
    "            sample_perplexity=sample_perp,\n",
    "            full_perplexity=full_perp,\n",
    "            rnd_state=42\n",
    "        )\n",
    "\n",
    "        # Evaluate quality metrics\n",
    "        mnn, mnn_global, rho = embedding_quality(\n",
    "            X=initial_embedding,\n",
    "            Z=final_embedding,\n",
    "            classes=labels,\n",
    "            knn=10,\n",
    "            knn_classes=4,\n",
    "            subsetsize=1000\n",
    "        )\n",
    "\n",
    "        # Subsample for CPD\n",
    "        subset_indices = np.random.choice(final_embedding.shape[0], size=1000, replace=False)\n",
    "        emb_subset = final_embedding[subset_indices, :]\n",
    "        cpd_value = None\n",
    "\n",
    "        if full_perp not in embedding_reference_by_full_perp:\n",
    "            embedding_reference_by_full_perp[full_perp] = emb_subset\n",
    "        else:\n",
    "            ref_embedding = embedding_reference_by_full_perp[full_perp]\n",
    "            d1 = pdist(ref_embedding)\n",
    "            d2 = pdist(emb_subset)\n",
    "            cpd_value = spearmanr(d1, d2).correlation\n",
    "\n",
    "            cpd_between_columns_records.append({\n",
    "                \"full_perplexity\": full_perp,\n",
    "                \"sample_perplexity\": sample_perp,\n",
    "                \"cpd_value\": cpd_value\n",
    "            })\n",
    "\n",
    "        columnwise_results.append({\n",
    "            \"sample_perplexity\": sample_perp,\n",
    "            \"full_perplexity\": full_perp,\n",
    "            \"embedding\": final_embedding,\n",
    "            \"labels\": labels,\n",
    "            \"mnn\": mnn,\n",
    "            \"knc\": mnn_global,\n",
    "            \"cpd\": rho\n",
    "        })\n",
    "\n",
    "        print(\"Done\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760423b",
   "metadata": {},
   "source": [
    "#### Generate csv file containing cpd values between embeddings across the columns and save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "cpd_col_df = pd.DataFrame(cpd_between_columns_records)\n",
    "\n",
    "# Save CSV\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "folder_timestamp = datetime.now().strftime(\"%d-%m-%y\")\n",
    "cpd_col_dir = Path.cwd() / \"figures\" / \"multi-grid\" / \"fast_tsne\" / \"tasic\" / folder_timestamp\n",
    "cpd_col_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cpd_col_filename = f\"tasic_cpd_colwise_{datetime.now().strftime('%H-%M-%S')}.csv\"\n",
    "cpd_col_path = cpd_col_dir / cpd_col_filename\n",
    "cpd_col_df.to_csv(cpd_col_path, index=False)\n",
    "print(f\"Saved CPD (column-wise) to {cpd_col_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-emb-exps-kb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
